# logistic-regression-self-implemented
Logistic and Softmax Regression via Gradient Descent using NumPy only


Logistic regression and Softmax regression are classification tools used in creating training models. In this project, these regressions were implemented from scratch along with Batch and Stochastic Gradient Descent using NumPy only. I investigated to the extent of their effectiveness when considering Batch and Stochastic Gradient Descent. General optimization of the algorithms was found by attempting different learning rates and epochs amount.


This projects includes:
* California Facial Expressions (CAFE) dataset organization by PCA, encoding and smart train\validation\test segmentation.
* Basic Data Visualization after PCA for different expressions.
* Batch and Stochastic Gradient Descent implementation.
* Softmax Activation, log-likelihood, Cross Entropy functions implementation.
* Calculations of loss of each iteration (batch).
* Training, evaluation and methods comparition process using the above.
